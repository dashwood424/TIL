{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 추천 시스템\n",
    "* 협업 필터링: 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식만을 기반으로 추천을 수행하는 것\n",
    "    * 최근접 이웃 방식\n",
    "        * 사용자 기반 : 특정 사용자와 유사한 다른 사용자를 TOP-N으로 선정해 이 TOP-N 사용자가 좋아하는 아이템을 추천하는 방식. 특정 사용자와 타 사용자 간의 유사도를 측정한 뒤 유사도가 가장 높은 TOP-N 사용자를 추출해 그들이 선호하는 아이템을 추천하는 것\n",
    "        * 아이템 기반 : 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을 추천하는 기준이 되는 알고리즘. \n",
    "        * 아이템 기반 협업 필터링이 정확도가 더 높음\n",
    "    * 잠재 요인 방식\n",
    "        * 사용자-아이템 평점 매트릭스 속에 숨어있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법\n",
    "        * 행렬 분해\n",
    "            * 주로 SVD방식을 이용하나 Null값이 있는 경우 사용하지 못함 -> 경사하강법 이용\n",
    "        * 경사하강법\n",
    "            * P와 Q 행렬로 계산된 예측 R행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용함수 최적화를 통해 P와 Q를 유추"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**경사하강법을 이용해 행렬분해를 수행하는 과정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정\n",
    "R=np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
    "           [np.NaN, 5, np.NaN, 3, 1], \n",
    "           [np.NaN, np.NaN, 3, 4, 4],\n",
    "           [5, 2, 1, 2, np.NaN]])\n",
    "\n",
    "num_users, num_items=R.shape\n",
    "K=3\n",
    "\n",
    "# P와 Q행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력\n",
    "np.random.seed(1)\n",
    "P=np.random.normal(scale=1./K, size=(num_users, K))\n",
    "Q=np.random.normal(scale=1./K, size=(num_items, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실제 행렬과 예측 행렬의 오차 구하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error=0;\n",
    "    # 두 개의 분해된 행렬 P와 Q.T의 내적으로 예측 행렬 R 생성\n",
    "    full_pred_matrix=np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R행렬에서 널이 아닌 값의 위치 인덱스를 추출해 실제 R행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind=[non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind=[non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros=R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros=full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    mse=mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse=np.sqrt(mse)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step:  0  rmse:  10.659037853664685\n",
      "### iteration step:  0  rmse:  10.663183505301207\n",
      "### iteration step:  0  rmse:  10.645613047299983\n",
      "### iteration step:  0  rmse:  10.644346084939555\n",
      "### iteration step:  0  rmse:  10.645581949897782\n",
      "### iteration step:  0  rmse:  10.643328122261329\n",
      "### iteration step:  0  rmse:  10.626349009530133\n",
      "### iteration step:  0  rmse:  10.622087609323627\n",
      "### iteration step:  0  rmse:  10.611045186349452\n",
      "### iteration step:  0  rmse:  10.614228003433338\n",
      "### iteration step:  0  rmse:  10.61433525373386\n",
      "### iteration step:  0  rmse:  10.612784895036869\n",
      "### iteration step:  50  rmse:  0.4826847637377499\n",
      "### iteration step:  50  rmse:  0.4809214258571381\n",
      "### iteration step:  50  rmse:  0.4787702501177038\n",
      "### iteration step:  50  rmse:  0.47840583761081873\n",
      "### iteration step:  50  rmse:  0.476797573736393\n",
      "### iteration step:  50  rmse:  0.4744591769196104\n",
      "### iteration step:  50  rmse:  0.46878465911555617\n",
      "### iteration step:  50  rmse:  0.45833490938885996\n",
      "### iteration step:  50  rmse:  0.4490521867277673\n",
      "### iteration step:  50  rmse:  0.4450631375851286\n",
      "### iteration step:  50  rmse:  0.4452550055111111\n",
      "### iteration step:  50  rmse:  0.44826620293356795\n",
      "### iteration step:  100  rmse:  0.09021046499149528\n",
      "### iteration step:  100  rmse:  0.09063140161465007\n",
      "### iteration step:  100  rmse:  0.09064004528150708\n",
      "### iteration step:  100  rmse:  0.09021986891796739\n",
      "### iteration step:  100  rmse:  0.09017268644375746\n",
      "### iteration step:  100  rmse:  0.09021348377888012\n",
      "### iteration step:  100  rmse:  0.08987140734047461\n",
      "### iteration step:  100  rmse:  0.08931498007752652\n",
      "### iteration step:  100  rmse:  0.0888799860670083\n",
      "### iteration step:  100  rmse:  0.08878726950931258\n",
      "### iteration step:  100  rmse:  0.08886104396442264\n",
      "### iteration step:  100  rmse:  0.08869250942761936\n",
      "### iteration step:  150  rmse:  0.05544070183106007\n",
      "### iteration step:  150  rmse:  0.055654238581560656\n",
      "### iteration step:  150  rmse:  0.05566542568292506\n",
      "### iteration step:  150  rmse:  0.05537291765390037\n",
      "### iteration step:  150  rmse:  0.05539459614666814\n",
      "### iteration step:  150  rmse:  0.05534984563867542\n",
      "### iteration step:  150  rmse:  0.055068144454276845\n",
      "### iteration step:  150  rmse:  0.05498298471089022\n",
      "### iteration step:  150  rmse:  0.05470852741689072\n",
      "### iteration step:  150  rmse:  0.05468632137568407\n",
      "### iteration step:  150  rmse:  0.05477369683308786\n",
      "### iteration step:  150  rmse:  0.05484445221367373\n",
      "### iteration step:  200  rmse:  0.03953296121896474\n",
      "### iteration step:  200  rmse:  0.03964627794203618\n",
      "### iteration step:  200  rmse:  0.03965985158572862\n",
      "### iteration step:  200  rmse:  0.03944771813396079\n",
      "### iteration step:  200  rmse:  0.03946237802881643\n",
      "### iteration step:  200  rmse:  0.0394215665366636\n",
      "### iteration step:  200  rmse:  0.03917956945179083\n",
      "### iteration step:  200  rmse:  0.039153181295642554\n",
      "### iteration step:  200  rmse:  0.03895211121542946\n",
      "### iteration step:  200  rmse:  0.038939246516641844\n",
      "### iteration step:  200  rmse:  0.03900474097543347\n",
      "### iteration step:  200  rmse:  0.039155231598029146\n",
      "### iteration step:  250  rmse:  0.02949013140014387\n",
      "### iteration step:  250  rmse:  0.029555127593933413\n",
      "### iteration step:  250  rmse:  0.029568836029146995\n",
      "### iteration step:  250  rmse:  0.029405665964707218\n",
      "### iteration step:  250  rmse:  0.029417296899611433\n",
      "### iteration step:  250  rmse:  0.029391163352065427\n",
      "### iteration step:  250  rmse:  0.029199464709560936\n",
      "### iteration step:  250  rmse:  0.029184668535728642\n",
      "### iteration step:  250  rmse:  0.02902832368424468\n",
      "### iteration step:  250  rmse:  0.029018543729829233\n",
      "### iteration step:  250  rmse:  0.029065083722532015\n",
      "### iteration step:  250  rmse:  0.02922750101622652\n",
      "### iteration step:  300  rmse:  0.02274212881981338\n",
      "### iteration step:  300  rmse:  0.022781660032138152\n",
      "### iteration step:  300  rmse:  0.022794601787029273\n",
      "### iteration step:  300  rmse:  0.02266390973599952\n",
      "### iteration step:  300  rmse:  0.022674475215670953\n",
      "### iteration step:  300  rmse:  0.022660411599298602\n",
      "### iteration step:  300  rmse:  0.02251163729779163\n",
      "### iteration step:  300  rmse:  0.02249997614264998\n",
      "### iteration step:  300  rmse:  0.02237282733253067\n",
      "### iteration step:  300  rmse:  0.022364681508136964\n",
      "### iteration step:  300  rmse:  0.0223974704214137\n",
      "### iteration step:  300  rmse:  0.022551082763646108\n",
      "### iteration step:  350  rmse:  0.01805001578236827\n",
      "### iteration step:  350  rmse:  0.018074910089672838\n",
      "### iteration step:  350  rmse:  0.018086784905833493\n",
      "### iteration step:  350  rmse:  0.017979087072714398\n",
      "### iteration step:  350  rmse:  0.017989268349546225\n",
      "### iteration step:  350  rmse:  0.017983586082645227\n",
      "### iteration step:  350  rmse:  0.017867347903235485\n",
      "### iteration step:  350  rmse:  0.017856677549647964\n",
      "### iteration step:  350  rmse:  0.01774955319260076\n",
      "### iteration step:  350  rmse:  0.0177425113967772\n",
      "### iteration step:  350  rmse:  0.017765675496428886\n",
      "### iteration step:  350  rmse:  0.017905567270761674\n",
      "### iteration step:  400  rmse:  0.014686050453039482\n",
      "### iteration step:  400  rmse:  0.014701938209589815\n",
      "### iteration step:  400  rmse:  0.014712686961658094\n",
      "### iteration step:  400  rmse:  0.014622024928488521\n",
      "### iteration step:  400  rmse:  0.014632070265733035\n",
      "### iteration step:  400  rmse:  0.014631934476817198\n",
      "### iteration step:  400  rmse:  0.014539722087979637\n",
      "### iteration step:  400  rmse:  0.01452937361411324\n",
      "### iteration step:  400  rmse:  0.014436582669844605\n",
      "### iteration step:  400  rmse:  0.014430396068436496\n",
      "### iteration step:  400  rmse:  0.014446853943932164\n",
      "### iteration step:  400  rmse:  0.014573029093444156\n",
      "### iteration step:  450  rmse:  0.012207285743944757\n",
      "### iteration step:  450  rmse:  0.01221734104562719\n",
      "### iteration step:  450  rmse:  0.012226999782598426\n",
      "### iteration step:  450  rmse:  0.012149380618523796\n",
      "### iteration step:  450  rmse:  0.012159390456495542\n",
      "### iteration step:  450  rmse:  0.0121628445379443\n",
      "### iteration step:  450  rmse:  0.012088465219709675\n",
      "### iteration step:  450  rmse:  0.012078198447775452\n",
      "### iteration step:  450  rmse:  0.01199604125519592\n",
      "### iteration step:  450  rmse:  0.011990572001945685\n",
      "### iteration step:  450  rmse:  0.012002339187765458\n",
      "### iteration step:  450  rmse:  0.012116186348700778\n",
      "### iteration step:  500  rmse:  0.01033685707915063\n",
      "### iteration step:  500  rmse:  0.010342988069964575\n",
      "### iteration step:  500  rmse:  0.010351627998783182\n",
      "### iteration step:  500  rmse:  0.010284248847193278\n",
      "### iteration step:  500  rmse:  0.01029426981059268\n",
      "### iteration step:  500  rmse:  0.010299997325356323\n",
      "### iteration step:  500  rmse:  0.01023906016619482\n",
      "### iteration step:  500  rmse:  0.010228776879859082\n",
      "### iteration step:  500  rmse:  0.010154743274461793\n",
      "### iteration step:  500  rmse:  0.010149903838426646\n",
      "### iteration step:  500  rmse:  0.010158373991845862\n",
      "### iteration step:  500  rmse:  0.010261525529836788\n",
      "### iteration step:  550  rmse:  0.008896533944203852\n",
      "### iteration step:  550  rmse:  0.008899946687910519\n",
      "### iteration step:  550  rmse:  0.008907648910223063\n",
      "### iteration step:  550  rmse:  0.00884847244310736\n",
      "### iteration step:  550  rmse:  0.008858529727941404\n",
      "### iteration step:  550  rmse:  0.008865647799859612\n",
      "### iteration step:  550  rmse:  0.0088150262775043\n",
      "### iteration step:  550  rmse:  0.008804680380209163\n",
      "### iteration step:  550  rmse:  0.008737001879163828\n",
      "### iteration step:  550  rmse:  0.008732729851872519\n",
      "### iteration step:  550  rmse:  0.008738875365329425\n",
      "### iteration step:  550  rmse:  0.00883285323524387\n",
      "### iteration step:  600  rmse:  0.007768128672232945\n",
      "### iteration step:  600  rmse:  0.007769616193498829\n",
      "### iteration step:  600  rmse:  0.007776461052828407\n",
      "### iteration step:  600  rmse:  0.007723965082453284\n",
      "### iteration step:  600  rmse:  0.007734074262670455\n",
      "### iteration step:  600  rmse:  0.00774198923327758\n",
      "### iteration step:  600  rmse:  0.007699424244062722\n",
      "### iteration step:  600  rmse:  0.007688991000415347\n",
      "### iteration step:  600  rmse:  0.007626380394381185\n",
      "### iteration step:  600  rmse:  0.007622627073600598\n",
      "### iteration step:  600  rmse:  0.00762713381180084\n",
      "### iteration step:  600  rmse:  0.007713258926068283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step:  650  rmse:  0.006871060826379036\n",
      "### iteration step:  650  rmse:  0.006871161463091513\n",
      "### iteration step:  650  rmse:  0.006877224254368025\n",
      "### iteration step:  650  rmse:  0.006830245619597101\n",
      "### iteration step:  650  rmse:  0.006840417280251347\n",
      "### iteration step:  650  rmse:  0.00684872896133637\n",
      "### iteration step:  650  rmse:  0.006812559002439696\n",
      "### iteration step:  650  rmse:  0.006802023629205184\n",
      "### iteration step:  650  rmse:  0.006743517331703443\n",
      "### iteration step:  650  rmse:  0.006740242215160119\n",
      "### iteration step:  650  rmse:  0.006743599006297992\n",
      "### iteration step:  650  rmse:  0.006822987985846849\n",
      "### iteration step:  700  rmse:  0.00614899094321202\n",
      "### iteration step:  700  rmse:  0.006148079963171762\n",
      "### iteration step:  700  rmse:  0.0061534294737563945\n",
      "### iteration step:  700  rmse:  0.006111062455266679\n",
      "### iteration step:  700  rmse:  0.0061213042029873805\n",
      "### iteration step:  700  rmse:  0.0061297429351423955\n",
      "### iteration step:  700  rmse:  0.006098724039676091\n",
      "### iteration step:  700  rmse:  0.006088077065562549\n",
      "### iteration step:  700  rmse:  0.006032936017864428\n",
      "### iteration step:  700  rmse:  0.006030103996410979\n",
      "### iteration step:  700  rmse:  0.006032662403969292\n",
      "### iteration step:  700  rmse:  0.006106250723838792\n",
      "### iteration step:  750  rmse:  0.005561634407662286\n",
      "### iteration step:  750  rmse:  0.005559979427901536\n",
      "### iteration step:  750  rmse:  0.005564677739108959\n",
      "### iteration step:  750  rmse:  0.005526205656810091\n",
      "### iteration step:  750  rmse:  0.0055365231103951\n",
      "### iteration step:  750  rmse:  0.005544908158885386\n",
      "### iteration step:  750  rmse:  0.005518093161045377\n",
      "### iteration step:  750  rmse:  0.0055073283146937465\n",
      "### iteration step:  750  rmse:  0.005454973544630509\n",
      "### iteration step:  750  rmse:  0.00545255338760624\n",
      "### iteration step:  750  rmse:  0.005454568101857688\n",
      "### iteration step:  750  rmse:  0.005523138387034983\n",
      "### iteration step:  800  rmse:  0.005079607345954792\n",
      "### iteration step:  800  rmse:  0.005077403109178876\n",
      "### iteration step:  800  rmse:  0.0050815059387574225\n",
      "### iteration step:  800  rmse:  0.005046353769178801\n",
      "### iteration step:  800  rmse:  0.005056751118080718\n",
      "### iteration step:  800  rmse:  0.005064962877340808\n",
      "### iteration step:  800  rmse:  0.005041619351647551\n",
      "### iteration step:  800  rmse:  0.0050307324717838615\n",
      "### iteration step:  800  rmse:  0.004980701899036716\n",
      "### iteration step:  800  rmse:  0.00497866538360546\n",
      "### iteration step:  800  rmse:  0.004980321893047992\n",
      "### iteration step:  800  rmse:  0.0050445302942674726\n",
      "### iteration step:  850  rmse:  0.004681095359025268\n",
      "### iteration step:  850  rmse:  0.004678486238031459\n",
      "### iteration step:  850  rmse:  0.004682043488654218\n",
      "### iteration step:  850  rmse:  0.004649744243894471\n",
      "### iteration step:  850  rmse:  0.004660224601670671\n",
      "### iteration step:  850  rmse:  0.0046681857976632124\n",
      "### iteration step:  850  rmse:  0.004647739344423902\n",
      "### iteration step:  850  rmse:  0.004636727746848737\n",
      "### iteration step:  850  rmse:  0.004588646441199076\n",
      "### iteration step:  850  rmse:  0.004586967815222335\n",
      "### iteration step:  850  rmse:  0.004588401629938357\n",
      "### iteration step:  850  rmse:  0.00464880034035182\n",
      "### iteration step:  900  rmse:  0.0043496476566212885\n",
      "### iteration step:  900  rmse:  0.004346742605228261\n",
      "### iteration step:  900  rmse:  0.004349798963322933\n",
      "### iteration step:  900  rmse:  0.00431996933360864\n",
      "### iteration step:  900  rmse:  0.004330534980745805\n",
      "### iteration step:  900  rmse:  0.004338197803862103\n",
      "### iteration step:  900  rmse:  0.0043201921677385215\n",
      "### iteration step:  900  rmse:  0.00430905424177078\n",
      "### iteration step:  900  rmse:  0.004262613450705374\n",
      "### iteration step:  900  rmse:  0.004261269075449689\n",
      "### iteration step:  900  rmse:  0.004262579261820414\n",
      "### iteration step:  900  rmse:  0.004319635056762576\n",
      "### iteration step:  950  rmse:  0.004072683757314674\n",
      "### iteration step:  950  rmse:  0.004069566473307816\n",
      "### iteration step:  950  rmse:  0.004072161988039837\n",
      "### iteration step:  950  rmse:  0.004044484371347517\n",
      "### iteration step:  950  rmse:  0.0040551369308668575\n",
      "### iteration step:  950  rmse:  0.004062474128730308\n",
      "### iteration step:  950  rmse:  0.004046542679171635\n",
      "### iteration step:  950  rmse:  0.004035277613509131\n",
      "### iteration step:  950  rmse:  0.003990219657240182\n",
      "### iteration step:  950  rmse:  0.003989187751481463\n",
      "### iteration step:  950  rmse:  0.003990446581688411\n",
      "### iteration step:  950  rmse:  0.004044555848949716\n"
     ]
    }
   ],
   "source": [
    "# R>0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장\n",
    "non_zeros=[(i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j]>0]\n",
    "\n",
    "steps=1000 # 반복 수행 횟수\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01 # L2규제 계수\n",
    "\n",
    "# SGD 기법으로 P와 Q 계속 업데이트\n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros:\n",
    "        # 실제 값과 예측 값의 차이인 오류값 구함\n",
    "        eij=r-np.dot(P[i, :], Q[j, :].T)\n",
    "        # regularization을 반영한 SGD 업데이트\n",
    "        P[i, :]=P[i, :]+learning_rate*(eij*Q[j, :]-r_lambda*P[i, :])\n",
    "        Q[j, :]=Q[j, :]+learning_rate*(eij*Q[i, :]-r_lambda*Q[j, :])\n",
    "        \n",
    "        rmse=get_rmse(R, P, Q, non_zeros)\n",
    "        if(step%50)==0:\n",
    "            print('### iteration step: ', step, ' rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 행렬:\n",
      " [[4.021 1.912 1.192 1.941 1.27 ]\n",
      " [4.314 4.995 1.991 2.949 1.015]\n",
      " [6.707 5.082 3.004 3.949 3.951]\n",
      " [4.91  1.97  0.985 2.157 0.188]]\n"
     ]
    }
   ],
   "source": [
    "pred_matrix=np.dot(P, Q.T)\n",
    "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "널인 값은 새로운 예측값으로 채워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
